"""
è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–ç‰ˆæœ¬ - é’ˆå¯¹ç»ˆç«¯æœºéƒ¨ç½²
æ”¯æŒå¤šå¹³å°è‡ªåŠ¨æ£€æµ‹å’Œæ€§èƒ½è‡ªé€‚åº”
"""
import cv2
import threading
import platform
import signal
import sys
import time
import logging
import numpy as np
import os
from collections import deque
from queue import Queue, Empty
from flask import Flask, Response, jsonify, request
from flask_cors import CORS
from ultralytics import YOLO

# å¯¼å…¥è®¾å¤‡é…ç½®
from device_config import get_device_config, get_model_path, print_device_info

app = Flask(__name__)
CORS(app)

# --- ä»ç¯å¢ƒå˜é‡æˆ–å‘½ä»¤è¡Œå‚æ•°è·å–è®¾å¤‡ç±»å‹ ---
DEVICE_TYPE = os.getenv('DEVICE_TYPE', None)
if len(sys.argv) > 1:
    DEVICE_TYPE = sys.argv[1]

# è·å–è®¾å¤‡é…ç½®
CONFIG, detected_device_type = get_device_config(DEVICE_TYPE)

# è·å–æ¨¡å‹è·¯å¾„å¹¶æ£€æŸ¥
try:
    MODEL_PATH = get_model_path(CONFIG['model_size'])
    if not os.path.exists(MODEL_PATH):
        logging.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
        logging.error("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨ server/ ç›®å½•ä¸‹")
        logging.error("å¯ç”¨æ¨¡å‹: fire_m.pt, yolov8n.pt, yolov8s.pt")
        sys.exit(1)
except FileNotFoundError as e:
    logging.error(f"âŒ {e}")
    logging.error("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨")
    sys.exit(1)

# --- æ—¥å¿—é…ç½® ---
log_level = logging.DEBUG if os.getenv('DEBUG', '0') == '1' else logging.INFO
logging.basicConfig(
    level=log_level,
    format='[%(asctime)s] %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# æ‰“å°è®¾å¤‡ä¿¡æ¯
print_device_info(CONFIG, detected_device_type)

# --- å…¨å±€ç»Ÿè®¡ ---
stats = {
    'total_frames': 0,
    'detected_fires': 0,
    'detected_smoke': 0,
    'current_fps': 0.0,
    'inference_fps': 0.0,
    'last_detection_time': None,
    'cpu_usage': 0.0,
    'memory_usage': 0.0,
}

# --- åŠ è½½æ¨¡å‹ ---
logging.info(f"æ­£åœ¨åŠ è½½ YOLO æ¨¡å‹ ({MODEL_PATH})...")
try:
    model = YOLO(MODEL_PATH)
    
    # è®¾ç½®è®¾å¤‡
    device = 'cuda' if CONFIG['use_gpu'] else 'cpu'
    if device == 'cuda':
        try:
            import torch
            if torch.cuda.is_available():
                logging.info(f"ğŸš€ CUDA å°±ç»ª! ä½¿ç”¨æ˜¾å¡: {torch.cuda.get_device_name(0)}")
            else:
                logging.warning("âš ï¸ CUDA ä¸å¯ç”¨! åˆ‡æ¢åˆ° CPU")
                device = 'cpu'
        except:
            device = 'cpu'
    
    if device == 'cpu':
        logging.info("ğŸ’» ä½¿ç”¨ CPU æ¨¡å¼")
    
    # æ¨¡å‹é¢„çƒ­
    logging.info("æ­£åœ¨é¢„çƒ­æ¨¡å‹...")
    warmup_resolution = CONFIG['resolution']
    dummy_frame = np.zeros((warmup_resolution[1], warmup_resolution[0], 3), dtype=np.uint8)
    _ = model(dummy_frame, conf=CONFIG['detection_conf'], verbose=False, device=device)
    logging.info("âœ… æ¨¡å‹é¢„çƒ­å®Œæˆ")
    
except Exception as e:
    logging.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥! é”™è¯¯: {e}", exc_info=True)
    sys.exit(1)


# --- æ‘„åƒå¤´ç®¡ç†ç±»ï¼ˆè¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–ç‰ˆï¼‰---
class EdgeCamera:
    def __init__(self, source=0):
        self.current_source = source
        self.video = None
        self.lock = threading.Lock()
        self.fail_count = 0
        self.last_frame = None
        self.last_results = None  # ç¼“å­˜æ£€æµ‹ç»“æœ
        self.frame_counter = 0
        self.inference_times = deque(maxlen=30)  # æ¨ç†æ—¶é—´ç»Ÿè®¡
        
        # å¤šçº¿ç¨‹æ¨ç†é˜Ÿåˆ—
        self.frame_queue = Queue(maxsize=2)  # é™åˆ¶é˜Ÿåˆ—å¤§å°é¿å…å†…å­˜æº¢å‡º
        self.result_queue = Queue(maxsize=2)
        self.inference_thread = None
        self.running = True
        
        self.open_camera(source)
        self.start_inference_thread()

    def _choose_backend(self):
        """æ ¹æ®ç³»ç»Ÿé€‰æ‹©æœ€ä½³çš„æ‘„åƒå¤´åç«¯"""
        system = platform.system()
        if system == 'Windows':
            return cv2.CAP_DSHOW
        elif system == 'Linux':
            return cv2.CAP_V4L2
        else:
            return 0

    def open_camera(self, source):
        """åˆ‡æ¢æ‘„åƒå¤´"""
        with self.lock:
            if self.video is not None:
                try:
                    self.video.release()
                except Exception as e:
                    logging.warning(f"é‡Šæ”¾æ‘„åƒå¤´æ—¶å‡ºé”™: {e}")
                time.sleep(0.5)

            backend = self._choose_backend()
            
            try:
                if backend:
                    self.video = cv2.VideoCapture(source, backend)
                else:
                    self.video = cv2.VideoCapture(source)
            except Exception as e:
                logging.warning(f"ä½¿ç”¨åç«¯å‚æ•°æ‰“å¼€å¤±è´¥: {e}")
                self.video = cv2.VideoCapture(source)

            if not self.video.isOpened():
                logging.warning(f"å¸¦åç«¯å‚æ•°æ‰“å¼€å¤±è´¥ï¼Œå°è¯•é»˜è®¤æ–¹å¼...")
                self.video = cv2.VideoCapture(source)

            # è®¾ç½®åˆ†è¾¨ç‡å’Œç¼“å†²åŒº
            if self.video.isOpened():
                try:
                    width, height = CONFIG['resolution']
                    self.video.set(cv2.CAP_PROP_FRAME_WIDTH, width)
                    self.video.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
                    self.video.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # æœ€å°ç¼“å†²åŒºå‡å°‘å»¶è¿Ÿ
                    # è®¾ç½®å¸§ç‡ï¼ˆå¦‚æœæ”¯æŒï¼‰
                    self.video.set(cv2.CAP_PROP_FPS, CONFIG['target_fps'])
                except Exception as e:
                    logging.warning(f"è®¾ç½®æ‘„åƒå¤´å‚æ•°æ—¶å‡ºé”™: {e}")

            if self.video.isOpened():
                self.current_source = source
                self.fail_count = 0
                logging.info(f"ğŸ“· æ‘„åƒå¤´å·²åˆ‡æ¢è‡³ç´¢å¼•: {source}")
            else:
                logging.error(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ç´¢å¼•: {source}")

    def start_inference_thread(self):
        """å¯åŠ¨æ¨ç†çº¿ç¨‹ï¼ˆå¼‚æ­¥å¤„ç†ï¼‰"""
        def inference_worker():
            while self.running:
                try:
                    # ä»é˜Ÿåˆ—è·å–å¸§ï¼ˆå¸¦è¶…æ—¶ï¼‰
                    frame_data = self.frame_queue.get(timeout=1.0)
                    if frame_data is None:
                        continue
                    
                    frame, frame_id = frame_data
                    
                    # æ‰§è¡Œæ¨ç†
                    start_time = time.time()
                    results = model(
                        frame,
                        conf=CONFIG['detection_conf'],
                        verbose=False,
                        device=device
                    )
                    inference_time = time.time() - start_time
                    self.inference_times.append(inference_time)
                    
                    # è®¡ç®—æ¨ç†FPS
                    if len(self.inference_times) > 1:
                        stats['inference_fps'] = 1.0 / (sum(self.inference_times) / len(self.inference_times))
                    
                    # å¤„ç†æ£€æµ‹ç»“æœ
                    has_danger = False
                    if len(results[0].boxes) > 0:
                        detected_cls_ids = results[0].boxes.cls.cpu().numpy()
                        confidences = results[0].boxes.conf.cpu().numpy()
                        names = results[0].names
                        
                        for cls_id, conf in zip(detected_cls_ids, confidences):
                            class_name = names[int(cls_id)]
                            if class_name == 'fire':
                                has_danger = True
                                stats['detected_fires'] += 1
                                stats['last_detection_time'] = time.time()
                                logging.warning(f"ğŸ”¥ æ£€æµ‹åˆ°ç«ç„°! ç½®ä¿¡åº¦: {conf:.2f}")
                            elif class_name == 'smoke':
                                has_danger = True
                                stats['detected_smoke'] += 1
                                stats['last_detection_time'] = time.time()
                                logging.warning(f"ğŸ’¨ æ£€æµ‹åˆ°çƒŸé›¾! ç½®ä¿¡åº¦: {conf:.2f}")
                    
                    # ç»˜åˆ¶æ£€æµ‹æ¡†
                    annotated_frame = results[0].plot(line_width=3, font_size=1)
                    
                    # JPEGç¼–ç 
                    encode_params = [cv2.IMWRITE_JPEG_QUALITY, CONFIG['jpeg_quality']]
                    ret, jpeg = cv2.imencode('.jpg', annotated_frame, encode_params)
                    
                    if ret:
                        # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
                        self.result_queue.put((jpeg.tobytes(), frame_id, has_danger))
                    
                except Empty:
                    continue
                except Exception as e:
                    logging.error(f"æ¨ç†çº¿ç¨‹å‡ºé”™: {e}", exc_info=True)
        
        self.inference_thread = threading.Thread(target=inference_worker, daemon=True)
        self.inference_thread.start()
        logging.info("âœ… æ¨ç†çº¿ç¨‹å·²å¯åŠ¨")

    def get_frame(self):
        """
        è·å–å¸§ï¼ˆå¼‚æ­¥æ¨ç†ç‰ˆæœ¬ï¼‰
        
        Returns:
            tuple: (jpeg_bytes, has_danger) æˆ– (None, False)
        """
        frame = None
        
        # è¯»å–å¸§
        with self.lock:
            if not self.video or not self.video.isOpened():
                self.fail_count += 1
                if self.fail_count >= 10:
                    logging.warning("æ‘„åƒå¤´æ–­å¼€ï¼Œå°è¯•é‡è¿...")
                    self.open_camera(self.current_source)
                return None, False
            
            success, frame = self.video.read()
            if not success or frame is None:
                self.fail_count += 1
                if self.fail_count >= 10:
                    self.open_camera(self.current_source)
                return None, False
            
            self.fail_count = 0

        # å¸§è·³è·ƒï¼šæ¯Nå¸§æ‰æ¨ç†ä¸€æ¬¡
        should_infer = (self.frame_counter % CONFIG['frame_skip'] == 0)
        self.frame_counter += 1
        
        if should_infer:
            # éœ€è¦æ¨ç†ï¼šå°†å¸§æ”¾å…¥é˜Ÿåˆ—
            try:
                self.frame_queue.put_nowait((frame.copy(), self.frame_counter))
            except:
                # é˜Ÿåˆ—æ»¡ï¼Œè·³è¿‡è¿™ä¸€å¸§
                pass
        
        # å°è¯•ä»ç»“æœé˜Ÿåˆ—è·å–æœ€æ–°ç»“æœ
        latest_result = None
        latest_id = -1
        
        # æ¸…ç©ºæ—§ç»“æœï¼Œåªä¿ç•™æœ€æ–°çš„
        while True:
            try:
                result = self.result_queue.get_nowait()
                if result[1] > latest_id:
                    latest_result = result
                    latest_id = result[1]
            except Empty:
                break
        
        if latest_result:
            jpeg_bytes, _, has_danger = latest_result
            self.last_frame = jpeg_bytes
            return jpeg_bytes, has_danger
        elif self.last_frame:
            # ä½¿ç”¨ç¼“å­˜çš„æœ€åä¸€å¸§
            return self.last_frame, False
        else:
            # æ²¡æœ‰ç»“æœï¼Œè¿”å›åŸå§‹å¸§
            encode_params = [cv2.IMWRITE_JPEG_QUALITY, CONFIG['jpeg_quality']]
            ret, jpeg = cv2.imencode('.jpg', frame, encode_params)
            if ret:
                return jpeg.tobytes(), False
            return None, False

    def release(self):
        """é‡Šæ”¾èµ„æº"""
        self.running = False
        with self.lock:
            if self.video is not None:
                try:
                    self.video.release()
                    logging.info("æ‘„åƒå¤´èµ„æºå·²é‡Šæ”¾")
                except Exception as e:
                    logging.warning(f"é‡Šæ”¾æ‘„åƒå¤´æ—¶å‡ºé”™: {e}")


# å…¨å±€æ‘„åƒå¤´å®ä¾‹
global_camera = EdgeCamera()


def generate_frames():
    """ç”Ÿæˆè§†é¢‘æµï¼ˆå¸¦å¸§ç‡æ§åˆ¶å’Œèµ„æºç›‘æ§ï¼‰"""
    target_fps = CONFIG['target_fps']
    frame_time = 1.0 / target_fps
    last_time = time.time()
    fps_buffer = deque(maxlen=30)
    
    # èµ„æºç›‘æ§é—´éš”
    last_stats_time = time.time()
    stats_interval = 5.0  # æ¯5ç§’æ›´æ–°ä¸€æ¬¡ç»Ÿè®¡
    
    while True:
        current_time = time.time()
        
        # å¸§ç‡æ§åˆ¶
        elapsed = current_time - last_time
        if elapsed < frame_time:
            time.sleep(frame_time - elapsed)
        
        last_time = time.time()
        fps_buffer.append(last_time)
        
        # è®¡ç®—FPS
        if len(fps_buffer) > 1:
            stats['current_fps'] = len(fps_buffer) / (fps_buffer[-1] - fps_buffer[0])
        
        # å®šæœŸæ›´æ–°èµ„æºä½¿ç”¨æƒ…å†µ
        if current_time - last_stats_time > stats_interval:
            try:
                import psutil
                stats['cpu_usage'] = psutil.cpu_percent(interval=0.1)
                stats['memory_usage'] = psutil.virtual_memory().percent
            except ImportError:
                pass
            except Exception:
                pass
            last_stats_time = current_time
        
        # è·å–å¸§
        frame_data, has_danger = global_camera.get_frame()
        stats['total_frames'] += 1
        
        if frame_data is None:
            time.sleep(0.01)
            continue
        
        # MJPEG æ ¼å¼æµ
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_data + b'\r\n')


# --- API è·¯ç”± ---

@app.route('/video_feed')
def video_feed():
    """è§†é¢‘æµæ¥å£"""
    return Response(
        generate_frames(),
        mimetype='multipart/x-mixed-replace; boundary=frame'
    )

@app.route('/api/cameras')
def get_cameras():
    """æ‰«æå¯ç”¨æ‘„åƒå¤´"""
    available_cameras = []
    for i in range(5):
        cap = None
        try:
            cap = cv2.VideoCapture(i)
            cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            if cap.isOpened():
                ret, _ = cap.read()
                if ret:
                    available_cameras.append({"id": i, "name": f"æ‘„åƒå¤´ {i}"})
        except Exception as e:
            logging.debug(f"æ£€æµ‹æ‘„åƒå¤´ {i} æ—¶å‡ºé”™: {e}")
        finally:
            if cap is not None:
                cap.release()
    return jsonify(available_cameras)

@app.route('/api/switch_camera', methods=['POST'])
def switch_camera():
    """åˆ‡æ¢æ‘„åƒå¤´"""
    try:
        data = request.json
        if not data:
            return jsonify({"status": "error", "message": "è¯·æ±‚ä½“ä¸ºç©º"}), 400
        new_index = int(data.get('index', 0))
        global_camera.open_camera(new_index)
        return jsonify({"status": "success", "message": f"å·²åˆ‡æ¢åˆ° {new_index}"})
    except Exception as e:
        logging.error(f"åˆ‡æ¢æ‘„åƒå¤´å¤±è´¥: {e}", exc_info=True)
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route('/api/stats')
def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    return jsonify({
        "total_frames": stats['total_frames'],
        "detected_fires": stats['detected_fires'],
        "detected_smoke": stats['detected_smoke'],
        "current_fps": round(stats['current_fps'], 2),
        "inference_fps": round(stats['inference_fps'], 2),
        "cpu_usage": round(stats['cpu_usage'], 1),
        "memory_usage": round(stats['memory_usage'], 1),
        "last_detection_time": stats['last_detection_time'],
        "device_config": {
            "name": CONFIG['name'],
            "resolution": f"{CONFIG['resolution'][0]}x{CONFIG['resolution'][1]}",
            "target_fps": CONFIG['target_fps'],
            "frame_skip": CONFIG['frame_skip'],
            "detection_conf": CONFIG['detection_conf'],
            "use_gpu": CONFIG['use_gpu'],
        }
    })

@app.route('/api/health')
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    camera_status = "ok" if (global_camera.video and global_camera.video.isOpened()) else "error"
    return jsonify({
        "status": "ok",
        "camera": camera_status,
        "model_loaded": model is not None,
        "device": device,
        "device_type": detected_device_type,
    })

@app.route('/api/config')
def get_config():
    """è·å–å½“å‰é…ç½®"""
    return jsonify(CONFIG)

@app.route('/api/debug_frame')
def debug_frame():
    """è°ƒè¯•æ¥å£ï¼ˆå…¼å®¹åŸç‰ˆï¼‰"""
    return jsonify({
        "message": "è¯·æŸ¥çœ‹ç»ˆç«¯æ—¥å¿—è¾“å‡º",
        "stats": stats,
        "config": CONFIG,
        "device_type": detected_device_type
    })


# --- ä¼˜é›…é€€å‡º ---
def _cleanup_and_exit(signum, frame):
    """æ¸…ç†èµ„æºå¹¶é€€å‡º"""
    logging.info('ğŸ‘‹ æœåŠ¡æ­£åœ¨åœæ­¢...')
    global_camera.release()
    sys.exit(0)

signal.signal(signal.SIGINT, _cleanup_and_exit)
signal.signal(signal.SIGTERM, _cleanup_and_exit)

if __name__ == '__main__':
    logging.info(f"ğŸš€ å¯åŠ¨è¾¹ç¼˜è®¾å¤‡æœåŠ¡å™¨ (ç«¯å£: 5000)")
    logging.info(f"ğŸ“Š è®¾å¤‡: {CONFIG['name']}")
    logging.info(f"ğŸ“Š æ¨¡å‹: {MODEL_PATH}")
    
    # å¯¼å…¥psutilç”¨äºèµ„æºç›‘æ§
    try:
        import psutil
    except ImportError:
        logging.warning("psutil æœªå®‰è£…ï¼Œèµ„æºç›‘æ§åŠŸèƒ½å°†ä¸å¯ç”¨")
        logging.warning("å»ºè®®å®‰è£…: pip install psutil")
    
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)

